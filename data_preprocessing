{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO0VVW/5GxKXxprfM46eafT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suarim/samsung_prism_camera_motion_estimation/blob/main/data_preprocessing\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KznhL07FgU-1",
        "outputId": "f1116479-8394-46ab-84d3-0e880d046048"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import division\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "from skimage.transform import resize\n",
        "\n",
        "import os\n",
        "import scipy.misc\n",
        "import imageio\n",
        "\n",
        "class kitti_raw_loader(object):\n",
        "    def __init__(self,\n",
        "                 dataset_dir,\n",
        "                 split,\n",
        "                 img_height=256,\n",
        "                 img_width=256,\n",
        "                 seq_length=5):\n",
        "        self.dataset_dir = dataset_dir\n",
        "        self.split = split\n",
        "        self.img_height = img_height\n",
        "        self.img_width = img_width\n",
        "        self.seq_length = seq_length\n",
        "        self.cam_ids = ['02', '03']\n",
        "        self.date_list = ['2011_09_26', '2011_09_28', '2011_09_29',\n",
        "                          '2011_09_30', '2011_10_03']\n",
        "        self.test_scenes = []\n",
        "        self.collect_static_frames()\n",
        "        self.collect_train_frames()\n",
        "\n",
        "    def collect_static_frames(self):\n",
        "        static_frames_file = os.path.join(self.dataset_dir, 'static_frames.txt')\n",
        "        with open(static_frames_file, 'r') as f:\n",
        "            frames = f.readlines()\n",
        "        self.static_frames = []\n",
        "        for fr in frames:\n",
        "            if fr == '\\n':\n",
        "                continue\n",
        "            date, drive, frame_id = fr.split(' ')\n",
        "            curr_fid = '%.10d' % (int(frame_id[:-1]))\n",
        "            for cid in self.cam_ids:\n",
        "                self.static_frames.append(drive + ' ' + cid + ' ' + curr_fid)\n",
        "\n",
        "    def collect_train_frames(self):\n",
        "        all_frames = []\n",
        "        for date in self.date_list:\n",
        "            drive_set = os.listdir(os.path.join(self.dataset_dir, date))\n",
        "            for dr in drive_set:\n",
        "                drive_dir = os.path.join(self.dataset_dir, date, dr)\n",
        "                if os.path.isdir(drive_dir):\n",
        "                    if dr[:-5] in self.test_scenes:\n",
        "                        continue\n",
        "                    for cam in self.cam_ids:\n",
        "                        img_dir = os.path.join(drive_dir, 'image_' + cam, 'data')\n",
        "                        N = len(glob(os.path.join(img_dir, '*.png')))\n",
        "                        for n in range(N):\n",
        "                            frame_id = '%.10d' % n\n",
        "                            all_frames.append(dr + ' ' + cam + ' ' + frame_id)\n",
        "\n",
        "        for s in self.static_frames:\n",
        "            try:\n",
        "                all_frames.remove(s)\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        self.train_frames = all_frames\n",
        "        self.num_train = len(self.train_frames)\n",
        "\n",
        "    def is_valid_sample(self, frames, tgt_idx):\n",
        "        N = len(frames)\n",
        "        tgt_drive, cid, _ = frames[tgt_idx].split(' ')\n",
        "        half_offset = int((self.seq_length - 1)/2)\n",
        "        min_src_idx = tgt_idx - half_offset\n",
        "        max_src_idx = tgt_idx + half_offset\n",
        "        if min_src_idx < 0 or max_src_idx >= N:\n",
        "            return False\n",
        "        min_src_drive, min_src_cid, _ = frames[min_src_idx].split(' ')\n",
        "        max_src_drive, max_src_cid, _ = frames[max_src_idx].split(' ')\n",
        "        if tgt_drive == min_src_drive and tgt_drive == max_src_drive and cid == min_src_cid and cid == max_src_cid:\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def get_train_example_with_idx(self, tgt_idx):\n",
        "        if not self.is_valid_sample(self.train_frames, tgt_idx):\n",
        "            return False\n",
        "        example = self.load_example(self.train_frames, tgt_idx)\n",
        "        return example\n",
        "\n",
        "    def load_image_sequence(self, frames, tgt_idx, seq_length):\n",
        "        half_offset = int((seq_length - 1)/2)\n",
        "        image_seq = []\n",
        "        for o in range(-half_offset, half_offset + 1):\n",
        "            curr_idx = tgt_idx + o\n",
        "            curr_drive, curr_cid, curr_frame_id = frames[curr_idx].split(' ')\n",
        "            curr_img = self.load_image_raw(curr_drive, curr_cid, curr_frame_id)\n",
        "            if o == 0:\n",
        "                zoom_y = self.img_height/curr_img.shape[0]\n",
        "                zoom_x = self.img_width/curr_img.shape[1]\n",
        "            curr_img = self.resize_image(curr_img, (self.img_height, self.img_width))\n",
        "            image_seq.append(curr_img)\n",
        "        return image_seq, zoom_x, zoom_y\n",
        "\n",
        "    def resize_image(self, image, size):\n",
        "        return resize(image, size, preserve_range=True).astype(image.dtype)\n",
        "    def load_example(self, frames, tgt_idx):\n",
        "        image_seq, zoom_x, zoom_y = self.load_image_sequence(frames, tgt_idx, self.seq_length)\n",
        "        tgt_drive, tgt_cid, tgt_frame_id = frames[tgt_idx].split(' ')\n",
        "        intrinsics = self.load_intrinsics_raw(tgt_drive, tgt_cid, tgt_frame_id)\n",
        "        intrinsics = self.scale_intrinsics(intrinsics, zoom_x, zoom_y)\n",
        "        example = {}\n",
        "        example['intrinsics'] = intrinsics\n",
        "        example['image_seq'] = image_seq\n",
        "        example['folder_name'] = tgt_drive + '_' + tgt_cid + '/'\n",
        "        example['file_name'] = tgt_frame_id\n",
        "        return example\n",
        "\n",
        "    def load_image_raw(self, drive, cid, frame_id):\n",
        "        date = drive[:10]\n",
        "        img_file = os.path.join(self.dataset_dir, date, drive, 'image_' + cid, 'data', frame_id + '.png')\n",
        "        img = imageio.imread(img_file)\n",
        "        return img\n",
        "\n",
        "    def load_intrinsics_raw(self, drive, cid, frame_id):\n",
        "        date = drive[:10]\n",
        "        calib_file = os.path.join(self.dataset_dir, date, 'calib_cam_to_cam.txt')\n",
        "\n",
        "        filedata = self.read_raw_calib_file(calib_file)\n",
        "        P_rect = np.reshape(filedata['P_rect_' + cid], (3, 4))\n",
        "        intrinsics = P_rect[:3, :3]\n",
        "        return intrinsics\n",
        "\n",
        "    def read_raw_calib_file(self,filepath):\n",
        "        # From https://github.com/utiasSTARS/pykitti/blob/master/pykitti/utils.py\n",
        "        \"\"\"Read in a calibration file and parse into a dictionary.\"\"\"\n",
        "        data = {}\n",
        "\n",
        "        with open(filepath, 'r') as f:\n",
        "            for line in f.readlines():\n",
        "                key, value = line.split(':', 1)\n",
        "                # The only non-float values in these files are dates, which\n",
        "                # we don't care about anyway\n",
        "                try:\n",
        "                    data[key] = np.array([float(x) for x in value.split()])\n",
        "                except ValueError:\n",
        "                    pass\n",
        "        return data\n",
        "\n",
        "    def scale_intrinsics(self, mat, sx, sy):\n",
        "        out = np.copy(mat)\n",
        "        out[0,0] *= sx\n",
        "        out[0,2] *= sx\n",
        "        out[1,1] *= sy\n",
        "        out[1,2] *= sy\n",
        "        return out\n",
        "\n"
      ],
      "metadata": {
        "id": "9L8ppuK8gpRV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import division\n",
        "import argparse\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "from joblib import Parallel, delayed\n",
        "from skimage.transform import resize\n",
        "\n",
        "import os\n",
        "\n",
        "# Define file paths\n",
        "dataset_dir = \"/content/drive/MyDrive/Prism/dummy\"\n",
        "dataset_name = \"kitti_raw_eigen\"  # Change this to your dataset name\n",
        "dump_root = \"/content/drive/MyDrive/Prism/dummy_dump\"\n",
        "seq_length = 10\n",
        "img_height = 128\n",
        "img_width = 416\n",
        "num_threads = 4\n",
        "\n",
        "# Define a function to concatenate image sequences\n",
        "def concat_image_seq(seq):\n",
        "    for i, im in enumerate(seq):\n",
        "        if i == 0:\n",
        "            res = im\n",
        "        else:\n",
        "            res = np.hstack((res, im))\n",
        "    return res\n",
        "\n",
        "# Define a function to process and dump examples\n",
        "def dump_example(n):\n",
        "    if n % 2000 == 0:\n",
        "        print('Progress %d/%d....' % (n, data_loader.num_train))\n",
        "    example = data_loader.get_train_example_with_idx(n)\n",
        "    if example == False:\n",
        "        return\n",
        "    image_seq = concat_image_seq(example['image_seq'])\n",
        "    intrinsics = example['intrinsics']\n",
        "    fx = intrinsics[0, 0]\n",
        "    fy = intrinsics[1, 1]\n",
        "    cx = intrinsics[0, 2]\n",
        "    cy = intrinsics[1, 2]\n",
        "    dump_dir = os.path.join(dump_root, example['folder_name'])\n",
        "    try:\n",
        "        os.makedirs(dump_dir)\n",
        "    except OSError:\n",
        "        if not os.path.isdir(dump_dir):\n",
        "            raise\n",
        "    dump_img_file = os.path.join(dump_dir, '%s.jpg' % example['file_name'])\n",
        "    imageio.imsave(dump_img_file, image_seq.astype(np.uint8))\n",
        "    dump_cam_file = os.path.join(dump_dir, '%s_cam.txt' % example['file_name'])\n",
        "    with open(dump_cam_file, 'w') as f:\n",
        "        f.write('%f,0.,%f,0.,%f,%f,0.,0.,1.' % (fx, cx, fy, cy))\n",
        "\n",
        "# Define the main function\n",
        "def main():\n",
        "    if not os.path.exists(dump_root):\n",
        "        os.makedirs(dump_root)\n",
        "\n",
        "    global data_loader\n",
        "    if dataset_name == 'kitti_odom':\n",
        "        from kitti.kitti_odom_loader import kitti_odom_loader\n",
        "        data_loader = kitti_odom_loader(dataset_dir,\n",
        "                                        img_height=img_height,\n",
        "                                        img_width=img_width,\n",
        "                                        seq_length=seq_length)\n",
        "\n",
        "    if dataset_name == 'kitti_raw_eigen':\n",
        "        data_loader = kitti_raw_loader(dataset_dir,\n",
        "                                       split='eigen',\n",
        "                                       img_height=img_height,\n",
        "                                       img_width=img_width,\n",
        "                                       seq_length=seq_length)\n",
        "\n",
        "    if dataset_name == 'kitti_raw_stereo':\n",
        "        data_loader = kitti_raw_loader(dataset_dir,\n",
        "                                       split='stereo',\n",
        "                                       img_height=img_height,\n",
        "                                       img_width=img_width,\n",
        "                                       seq_length=seq_length)\n",
        "\n",
        "    if dataset_name == 'cityscapes':\n",
        "        data_loader = cityscapes_loader(dataset_dir,\n",
        "                                        img_height=img_height,\n",
        "                                        img_width=img_width,\n",
        "                                        seq_length=seq_length)\n",
        "\n",
        "    Parallel(n_jobs=num_threads)(delayed(dump_example)(n) for n in range(data_loader.num_train))\n",
        "\n",
        "    # Split into train/val\n",
        "    np.random.seed(8964)\n",
        "    subfolders = os.listdir(dump_root)\n",
        "    with open(os.path.join(dump_root, 'train.txt'), 'w') as tf:\n",
        "        with open(os.path.join(dump_root, 'val.txt'), 'w') as vf:\n",
        "            for s in subfolders:\n",
        "                if not os.path.isdir(os.path.join(dump_root, s)):\n",
        "                    continue\n",
        "                imfiles = glob(os.path.join(dump_root, s, '*.jpg'))\n",
        "                frame_ids = [os.path.basename(fi).split('.')[0] for fi in imfiles]\n",
        "                for frame in frame_ids:\n",
        "                    if np.random.random() < 0.1:\n",
        "                        vf.write('%s %s\\n' % (s, frame))\n",
        "                    else:\n",
        "                        tf.write('%s %s\\n' % (s, frame))\n",
        "\n",
        "# Call the main function to start processing\n",
        "main()\n"
      ],
      "metadata": {
        "id": "dLrp_LU0g86h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}